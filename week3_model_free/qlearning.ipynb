{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qlearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuvDdNFk34gA",
        "colab_type": "text"
      },
      "source": [
        "## Q-learning\n",
        "\n",
        "This notebook will guide you through implementation of vanilla Q-learning algorithm.\n",
        "\n",
        "You need to implement QLearningAgent (follow instructions for each method) and use it on a number of tests below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beBWKLRJ34gC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "97a243b7-2f45-411a-b7e6-367eb0145ac4"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/spring20/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqq-2PYL34gG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Z5So_834gJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = float('-inf')\n",
        "        for action in possible_actions:\n",
        "            q_value = self.get_qvalue(state, action)\n",
        "            if q_value > value:\n",
        "                value = q_value\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "        current_q_value = self.get_qvalue(state, action)\n",
        "        new_q_value = (1 - learning_rate) * current_q_value + learning_rate * (reward + gamma * self.get_value(next_state))\n",
        "\n",
        "        self.set_qvalue(state, action, new_q_value)\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        best_q_value = float('-inf')\n",
        "        best_action = None\n",
        "        for action in possible_actions:\n",
        "            q_value = self.get_qvalue(state, action)\n",
        "            if q_value > best_q_value:\n",
        "                best_q_value = q_value\n",
        "                best_action = action\n",
        "\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.get_best_action).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        best_action = self.get_best_action(state)\n",
        "        random_action = random.choice(possible_actions)\n",
        "        random_value = random.random()\n",
        "        if random_value < epsilon:\n",
        "            chosen_action = random_action\n",
        "        else:\n",
        "            chosen_action = best_action\n",
        "\n",
        "        return chosen_action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s0p8gmx34gM",
        "colab_type": "text"
      },
      "source": [
        "### Try it on taxi\n",
        "\n",
        "Here we use the qlearning agent on taxi env from openai gym.\n",
        "You will need to insert a few agent functions here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjKzO0KD34gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "\n",
        "try:\n",
        "    env = gym.make('Taxi-v3')\n",
        "except gym.error.DeprecatedEnv:\n",
        "    # Taxi-v2 was replaced with Taxi-v3 in gym 0.15.0\n",
        "    env = gym.make('Taxi-v2')\n",
        "\n",
        "n_actions = env.action_space.n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb3RCp8m34gP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "                       get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqReu8h734gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"\n",
        "    This function should \n",
        "    - run a full game, actions given by agent's e-greedy policy\n",
        "    - train agent using agent.update(...) whenever it is possible\n",
        "    - return total reward\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # get agent to pick action given state s.\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "        # train (update) agent for state s\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m9eO3vc34gT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "de923ab1-04f4-411b-d5d6-e653654b4a34"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env, agent))\n",
        "    agent.epsilon *= 0.99\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
        "        plt.plot(rewards)\n",
        "        plt.show()\n",
        "        "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eps = 2.9191091959171894e-05 mean reward = 7.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4ESE2kD34gX",
        "colab_type": "text"
      },
      "source": [
        "### Submit to Coursera I: Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOwPuhy134gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_rewards1 = rewards.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Kk9zz534gZ",
        "colab_type": "text"
      },
      "source": [
        "# Binarized state spaces\n",
        "\n",
        "Use agent to train efficiently on CartPole-v0.\n",
        "This environment has a continuous set of possible states, so you will have to group them into bins somehow.\n",
        "\n",
        "The simplest way is to use `round(x,n_digits)` (or numpy round) to round real number to a given amount of digits.\n",
        "\n",
        "The tricky part is to get the n_digits right for each state to train effectively.\n",
        "\n",
        "Note that you don't need to convert state to integers, but to __tuples__ of any kind of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3AY2VM734ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"first state:%s\" % (env.reset()))\n",
        "plt.imshow(env.render('rgb_array'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3r--iRn34gc",
        "colab_type": "text"
      },
      "source": [
        "### Play a few games\n",
        "\n",
        "We need to estimate observation distributions. To do so, we'll play a few games and record all states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxyhK42j34gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_states = []\n",
        "for _ in range(1000):\n",
        "    all_states.append(env.reset())\n",
        "    done = False\n",
        "    while not done:\n",
        "        s, r, done, _ = env.step(env.action_space.sample())\n",
        "        all_states.append(s)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "all_states = np.array(all_states)\n",
        "\n",
        "for obs_i in range(env.observation_space.shape[0]):\n",
        "    plt.hist(all_states[:, obs_i], bins=20)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWYpw45a34ge",
        "colab_type": "text"
      },
      "source": [
        "## Binarize environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_3loEXz34ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gym.core import ObservationWrapper\n",
        "\n",
        "\n",
        "class Binarizer(ObservationWrapper):\n",
        "\n",
        "    def observation(self, state):\n",
        "\n",
        "        # state = <round state to some amount digits.>\n",
        "        # hint: you can do that with round(x,n_digits)\n",
        "        # you will need to pick a different n_digits for each dimension\n",
        "\n",
        "        return tuple(state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3aho2ZZ34gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = Binarizer(gym.make(\"CartPole-v0\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEl21VJf34gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_states = []\n",
        "for _ in range(1000):\n",
        "    all_states.append(env.reset())\n",
        "    done = False\n",
        "    while not done:\n",
        "        s, r, done, _ = env.step(env.action_space.sample())\n",
        "        all_states.append(s)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "all_states = np.array(all_states)\n",
        "\n",
        "for obs_i in range(env.observation_space.shape[0]):\n",
        "\n",
        "    plt.hist(all_states[:, obs_i], bins=20)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHaL0YD434gl",
        "colab_type": "text"
      },
      "source": [
        "## Learn binarized policy\n",
        "\n",
        "Now let's train a policy that uses binarized state space.\n",
        "\n",
        "__Tips:__ \n",
        "* If your binarization is too coarse, your agent may fail to find optimal policy. In that case, change binarization. \n",
        "* If your binarization is too fine-grained, your agent will take much longer than 1000 steps to converge. You can either increase number of iterations and decrease epsilon decay or change binarization.\n",
        "* Having 10^3 ~ 10^4 distinct states is recommended (`len(QLearningAgent._qvalues)`), but not required.\n",
        "* A reasonable agent should get to an average reward of >=50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8j9xoBY34gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "                       get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byMcy94134go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rewards = []\n",
        "for i in range(1000):\n",
        "    rewards.append(play_and_train(env, agent))\n",
        "\n",
        "    # OPTIONAL YOUR CODE: adjust epsilon\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
        "        plt.plot(rewards)\n",
        "        plt.show()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzdWhwa334gq",
        "colab_type": "text"
      },
      "source": [
        "### Submit to Coursera II: Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi6gPQC_34gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_rewards2 = rewards.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLwbWp5334gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from submit import submit_qlearning\n",
        "submit_qlearning(submit_rewards1, submit_rewards2, <EMAIL>, <TOKEN>)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}